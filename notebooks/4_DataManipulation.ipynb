{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Manipulates Raw Statistics into Multiple Forms #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Turns raw counts of game/player stats into\n",
    "- [x] Standardised\n",
    "- [x] Normalised\n",
    "- [x] Rank followed by Standardisation\n",
    "- [x] Percentages\n",
    "- [ ] Percentages followed by Standardisation       *[since proven to be exactly same as Standardisation]*\n",
    "- [x] Percentages followed by Normalisation\n",
    "\n",
    "*In order for different statistics to be used together for predictive purposes an important step is to manipulate them into a form which they are 'equal'. There are many ways to do so, and the author wanted to use different manipulations of data to see which gave the best results in terms of prediction. Also wanted to test in general the effectiveness of each data manipulation format*\n",
    "\n",
    "***Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: As Percentages followed by Standardisation was proven to be exactly the same as Standardisation, all relevent code have bben commented out* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Writing the functions for standardisation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that each method of manipulation contains 4 functions (except for percentage) is because of the existance of negative stats in which the scores should be reversed (i.e. turnovers, frees against). \n",
    "\n",
    "- BT means both teams - manipulates the data with respects to all players on ground\n",
    "- OT means own teams - manipulates the data with respect to only teammates\n",
    "- inv means inverse - the scores would be ranked in reverse (according to what is 'reverse' for that particular manipulated method)\n",
    "\n",
    "'Normalisation followed by Standardisation' or vice versa were initially also planned to be used, before an experiment showed that the former is equal to 'Standardisation' whilst the latter is exactly equal to 'Normalisation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(f'../data/curated/AFLCAVotes')\n",
    "filelist.sort()\n",
    "filelist = [file for file in filelist if file[0] != '.' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make dictionaries which direct the flow of control as to whether a column shoul receive manipulation and whether it should be positive or inversed direction.\n",
    "\n",
    "# Unchanged\n",
    "Orig = ['Player']\n",
    "\n",
    "# compare\n",
    "compare = ['Winloss','HomeAway', 'AFLCA_votes', 'Kicks', 'Handballs', 'Disposals', 'Marks', 'Goals', 'Behinds', 'Tackles', 'Hitouts', 'Goal Assists', 'Inside 50s', \n",
    "               'Clearances', 'Rebound 50s', 'Frees For', 'Contested Possessions', 'Uncontested Possessions', \n",
    "               'Effective Disposals', 'Contested Marks', 'Marks Inside 50', 'One Percenters', 'Bounces', 'Centre Clearances', \n",
    "               'Stoppage Clearances', 'Score Involvements', 'Metres Gained', 'Intercepts', 'Tackles Inside 50', 'Time On Ground %', 'Uncontested Marks',\n",
    "               'Marks Outside 50', 'Tackles Outside 50', 'Behind Assists', 'Effective Disposals', 'Ineffective Disposals', 'Brownlow Votes', 'Clangers', 'Turnovers', 'Frees Agains']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filelist:\n",
    "\n",
    "    if file[2:4] not in ['20', '21', '22']:\n",
    "        continue\n",
    "\n",
    "    if file in os.listdir(f'../data/curated/Head2Head'):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(f'../data/curated/AFLCAVotes/{file}')\n",
    "    df = df[df['Time On Ground %'] > 0.55] # below this time on ground no player has won Brownlow Votes (ever)\n",
    "\n",
    "    df['HomeAway'] = df['HomeAway'].apply(lambda x: 1 if x=='Home' else 0)\n",
    "\n",
    "    game_head2head_df_list = []\n",
    "\n",
    "    for player in df['Player']:\n",
    "        \n",
    "        one_player_df_list = []\n",
    "\n",
    "        player_stat = df[df['Player']==player]\n",
    "\n",
    "        for other_player in df['Player']:\n",
    "            if other_player == player:\n",
    "                continue\n",
    "            \n",
    "            other_player_stat = df[df['Player']==other_player]\n",
    "\n",
    "            head_2_head = {'player1': [player], 'player2': [other_player]}\n",
    "\n",
    "            for stat in compare:\n",
    "                \n",
    "                head_2_head[stat] = [player_stat[stat].values[0] - other_player_stat[stat].values[0]]\n",
    "    \n",
    "            head_2_head_df = pd.DataFrame(head_2_head)\n",
    "\n",
    "            one_player_df_list.append(head_2_head_df)\n",
    "\n",
    "        one_player_df = pd.concat(one_player_df_list)\n",
    "        game_head2head_df_list.append(one_player_df)  \n",
    "    \n",
    "    game_head2head_df = pd.concat(game_head2head_df_list)\n",
    "\n",
    "    game_head2head_df.to_parquet(f'../data/curated/Head2Head/{file.split(\".\")[0]}.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_2022_list = [x for x in os.listdir(f'../data/curated/Head2Head') if x[2:4] in ['21', '20']]\n",
    "is_2022_list = [x for x in os.listdir(f'../data/curated/Head2Head') if x[2:4] in ['22']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_games, val_test_games = train_test_split(non_2022_list, train_size = 0.7, random_state = 19260817)\n",
    "val_games, test_games = train_test_split(val_test_games, train_size = 0.5, random_state = 19260817)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = 0\n",
    "\n",
    "train_list = list()\n",
    "for file in train_games:\n",
    "\n",
    "    df = pd.read_parquet(f'../data/curated/Head2Head/{file}')\n",
    "    df['game_id'] = game_id\n",
    "\n",
    "    game_id += 1\n",
    "\n",
    "    train_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = 0\n",
    "\n",
    "val_list = list()\n",
    "for file in val_games:\n",
    "\n",
    "    df = pd.read_parquet(f'../data/curated/Head2Head/{file}')\n",
    "    df['game_id'] = game_id\n",
    "\n",
    "    game_id += 1\n",
    "\n",
    "    val_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = 0\n",
    "\n",
    "test_list = list()\n",
    "for file in val_games:\n",
    "\n",
    "    df = pd.read_parquet(f'../data/curated/Head2Head/{file}')\n",
    "    df['game_id'] = game_id\n",
    "\n",
    "    game_id += 1\n",
    "\n",
    "    test_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = 0\n",
    "\n",
    "future_list = list()\n",
    "for file in is_2022_list:\n",
    "\n",
    "    df = pd.read_parquet(f'../data/curated/Head2Head/{file}')\n",
    "    df['game_id'] = game_id\n",
    "\n",
    "    game_id += 1\n",
    "\n",
    "    future_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat(train_list)\n",
    "val_data = pd.concat(val_list)\n",
    "test_data = pd.concat(test_list)\n",
    "future_data = pd.concat(future_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_std = dict()\n",
    "\n",
    "for col in train_data:\n",
    "    if col == 'game_id':\n",
    "        continue\n",
    "    if train_data[col].dtype == np.float64:\n",
    "        col_std[col] = train_data[col].std()\n",
    "        train_data[col] = train_data[col]/col_std[col]\n",
    "\n",
    "        val_data[col] = val_data[col]/col_std[col]\n",
    "        test_data[col] = test_data[col]/col_std[col]\n",
    "        future_data[col] = future_data[col]/col_std[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_parquet('../data/curated/modelling/train_data.parquet')\n",
    "val_data.to_parquet('../data/curated/modelling/val_data.parquet')\n",
    "test_data.to_parquet('../data/curated/modelling/test_data.parquet')\n",
    "future_data.to_parquet('../data/curated/modelling/future_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/curated/stdev.json', 'w') as f:\n",
    "    json.dump(col_std, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
